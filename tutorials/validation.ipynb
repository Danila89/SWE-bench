{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec113f8e-56c1-44f7-9571-292c946bb6f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/swe-bench/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import glob, json, os, sys\n",
    "sys.path.append('/root/SWE-bench')\n",
    "sys.path.append('/root/SWE-bench/swebench/metrics') # TODO: Replace with path to `SWE-bench/swebench/metrics` folder\n",
    "from conversion import convert_log_to_ground_truth\n",
    "from getters import get_logs_gold\n",
    "from monitor import monitor_validation, monitor_logs_same_diff\n",
    "sys.path = sys.path[:-1]\n",
    "\n",
    "sys.path.append('/root/SWE-bench/swebench/harness') # TODO: Replace with path to `SWE-bench/swebench/harness` folder\n",
    "from utils import has_attribute_or_import_error\n",
    "sys.path = sys.path[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e965b7-702e-49d4-bc15-2619dc185752",
   "metadata": {},
   "source": [
    "Declare repository; Fetch tasks, logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c088f859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import glob \n",
    "\n",
    "# logs_list = glob.glob(\"/mnt/llm/home/ibragim-bad/data/swe_large/log_dir/*.log\") + glob.glob(\"/mnt/llm/home/ibragim-bad/data/swe_large_new/log_dir/*.json\")\n",
    "# inst = [l.split('/')[-1].split('.')[0] for l in  logs_list]\n",
    "# with open(\"/root/SWE-bench/swe_like_111k.json\") as f:\n",
    "#     tasks = json.load(f)\n",
    "# cut_tasks = [t for t in tasks if t['instance_id'] not in set(inst)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a328a462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import defaultdict\n",
    "\n",
    "# ct_dict = defaultdict(list)\n",
    "\n",
    "# for t in cut_tasks:\n",
    "#     ct_dict[t['repo']].append(t)\n",
    "\n",
    "# mx_len = max([len(v) for v in ct_dict.values()])\n",
    "# new_ct = []\n",
    "# for i in range(mx_len):\n",
    "#     for k in ct_dict:\n",
    "#         if i < len(ct_dict[k]):\n",
    "#             t = ct_dict[k][i]\n",
    "#             new_ct.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89234aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8699ec17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# N = 500\n",
    "\n",
    "\n",
    "\n",
    "# for i in range(0, len(new_ct), N):\n",
    "#     with open(f\"/root/data/swe/tasks_{i//N}.json\", \"w\") as f:\n",
    "#         json.dump(new_ct[i:i+N], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "194a1a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7f1692b3ebb0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/swe-bench/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "source": [
    "lst = open(\"/root/data/progress_2.txt\").readlines()\n",
    "lst = set([l.strip() for l in lst])\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "tasks = []\n",
    "tasks_dict = defaultdict(set)\n",
    "for l in lst:\n",
    "    with open(f\"/root/data/swe/{l}\") as f:\n",
    "        cur_t =  json.load(f)\n",
    "        tasks +=cur_t\n",
    "        for t in cur_t:\n",
    "            tasks_dict[l.split('/')[0]].add(t['instance_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0253bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c8353c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# l = {'swebench': {'resolved': {'count': 7, 'turns': {'avg': 9.571428571428571, 'median': 9.0, 'p90': 13.4}, 'opened_files': {'avg_precision': 0.8571428571428571, 'avg_recall': 1.0, 'avg_jaccard_similarity': 0.8571428571428571}, 'edit_loop_fraction': 0.14285714285714285, 'exit_cost_fraction': 0.0, 'patched_files': {'avg_precision': 0.9285714285714286, 'avg_recall': 1.0, 'avg_jaccard_similarity': 0.9285714285714286}}, 'failed': {'count': 88, 'turns': {'avg': 22.545454545454547, 'median': 16.5, 'p90': 45.3}, 'opened_files': {'avg_precision': 0.3901515151515151, 'avg_recall': 0.4431818181818182, 'avg_jaccard_similarity': 0.3901515151515151}, 'edit_loop_fraction': 0.25, 'exit_cost_fraction': 0.0, 'patched_files': {'avg_precision': 0.369047619047619, 'avg_recall': 0.45454545454545453, 'avg_jaccard_similarity': 0.369047619047619}}, 'skipped': {'count': 191, 'turns': {'avg': 39.02094240837696, 'median': 30.0, 'p90': 82.0}, 'opened_files': {'avg_precision': 0.22168638516806055, 'avg_recall': 0.31413612565445026, 'avg_jaccard_similarity': 0.22168638516806055}, 'edit_loop_fraction': 0.35602094240837695, 'exit_cost_fraction': 0.0}, 'ignored': {'count': 6}, 'total': {'count': 292}}}\n",
    "# print(json.dumps(l, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f1e9497-6e60-4027-8cee-790c8d0f1886",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo = 'pydicom/pydicom' # TODO: Replace with repository name\n",
    "log_dir = '/root/data/log_dir_2' # TODO: Replace with path to folder of execution logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba9ae3b-726c-40ec-8ed2-4012fc4f70dc",
   "metadata": {},
   "source": [
    "Get map of version to setup commit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "daa9d915-da85-4ca0-bba1-cd61ffeef3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tasks = json.load(open('path/to/pydicom-task-instances.json')) # TODO: Replace with path to versioned candidate task instances\n",
    "for t in tasks:\n",
    "    t[\"version\"] = \"0.0\"\n",
    "\n",
    "\n",
    "tasks = sorted(tasks, key=lambda x: x['created_at'], reverse=True)\n",
    "\n",
    "version_to_setup_commit = {}\n",
    "for t in tasks:\n",
    "    if 'version' in t and t['version'] not in version_to_setup_commit:\n",
    "        version_to_setup_commit[t['version']] = t['base_commit']\n",
    "assert(\n",
    "    sorted(list([x or \"\" for x in version_to_setup_commit.keys()])) ==\n",
    "    sorted(list(set([t['version'] or \"\" for t in tasks if 'version' in t])))\n",
    ")\n",
    "tasks = {t['instance_id']: t for t in tasks}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5edceae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0994a4a9-fd3d-4554-90b7-24b10c499b8a",
   "metadata": {},
   "source": [
    "#### Monitor Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5fcd54c-1a45-41f9-8a9c-64e9ff9df31a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Attempts: 77492\n",
      "Failed: 48903\n",
      "Usable: 28589\n",
      "Corrupt Test: 385\n",
      "Corrupt Diff: 225\n",
      "Test Script Timeout: 309\n",
      "Success E2E: 27670\n"
     ]
    }
   ],
   "source": [
    "failed_install, corrupt_test_patch, corrupt_patch, timeout, success = monitor_validation(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8d61d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = failed_install + success\n",
    "fs = set([f.split('/')[-1].split('.')[0] for f in fs if f])\n",
    "\n",
    "co = {}\n",
    "for t in tasks_dict:\n",
    "    co[t] = len(tasks_dict[t] & fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "008062a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nums = []\n",
    "for c in sorted(co):\n",
    "    if co[c] == 0:\n",
    "        nums.append(c.split('_')[1].split('.')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "babc3497",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join((nums))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "48cecde2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67850"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([f for f in failed_install if '0.0' not in f]) + len(success)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c6edea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeouts = 0\n",
    "timeout_installs = []\n",
    "for fp in failed_install:\n",
    "    with open(fp) as f:\n",
    "        l = f.read()\n",
    "        if '>>>>> Init Timed Out' in l:\n",
    "            timeouts+=1\n",
    "            timeout_installs.append(fp.split('/')[-1].split('.')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4485de37",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/root/SWE-bench/swe_like_111k.json\") as f:\n",
    "    tasks = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bbbaeec6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11956"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hst = set(timeout_installs)\n",
    "timeout_tasks = [t for t in tasks if t['instance_id'] in hst]\n",
    "len(timeout_tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d3eccb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "same = [fp.split('/')[-1].split('.')[0] for fp in logs_same]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1f13d91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 500\n",
    "\n",
    "hss = set(same)\n",
    "same_tasks = [t for t in tasks if t['instance_id'] in hss]\n",
    "len(same_tasks)\n",
    "\n",
    "\n",
    "for i in range(0, len(same_tasks), N):\n",
    "    with open(f\"/root/data/swe/same_{i//N}.json\", \"w\") as f:\n",
    "        json.dump(same_tasks[i:i+N], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a613db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5986eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 500\n",
    "\n",
    "\n",
    "\n",
    "for i in range(0, len(timeout_tasks), N):\n",
    "    with open(f\"/root/data/swe/timeouts_{i//N}.json\", \"w\") as f:\n",
    "        json.dump(timeout_tasks[i:i+N], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6cb6534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'base_commit': 'b501c92485576298b7ef46e7ab64b188b0f8ab3d',\n",
       " 'created_at': '2021-02-10T16:06:41Z',\n",
       " 'hints_text': '',\n",
       " 'instance_id': 'geoscixyz__geosci-labs-32',\n",
       " 'issue_numbers': [30],\n",
       " 'meta': {'failed_lite_validators': ['has_short_problem_statement',\n",
       "   'has_removed_files'],\n",
       "  'has_test_patch': True,\n",
       "  'is_lite': False},\n",
       " 'patch': 'diff --git a/.travis.yml b/.travis.yml\\ndeleted file mode 100644\\nindex 45e7082..0000000\\n--- a/.travis.yml\\n+++ /dev/null\\n@@ -1,56 +0,0 @@\\n-language: python\\n-python:\\n-  - 3.6\\n-\\n-sudo: false\\n-\\n-env:\\n-  global:\\n-    - PYPI_PY=3.6  # deploy to pypi from python 3.6\\n-    - TWINE_USERNAME=lheagy\\n-\\n-env:\\n-  - TEST=test_dcip.py\\n-  - TEST=test_em.py\\n-  - TEST=test_gpr.py\\n-  - TEST=test_inversion.py\\n-  - TEST=test_mag.py\\n-  - TEST=test_seismic.py\\n-  - TEST=test_gravity.py\\n-  - TEST=style\\n-\\n-# Setup anaconda\\n-before_install:\\n-# Install packages\\n-  - wget https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh -O miniconda.sh;\\n-  - chmod +x miniconda.sh\\n-  - ./miniconda.sh -b -p $HOME/miniconda\\n-  - export PATH=/home/travis/anaconda/bin:/home/travis/miniconda/bin:$PATH\\n-  - conda update --yes conda\\n-\\n-install:\\n-  - conda env create -f environment-dev.yml\\n-  - source activate geosci-labs-dev\\n-  - pip install -e .\\n-\\n-\\n-# Run test\\n-script:\\n-  - if [ $TEST == \"style\" ]; then\\n-      make check ;\\n-    else\\n-      pytest tests/$TEST -v -s ;\\n-    fi\\n-\\n-# upload to pypi on success and new tag\\n-deploy:\\n-  - provider: script\\n-    script: ci/deploy-pypi.sh\\n-    on:\\n-        tags: true\\n-        branch: master\\n-\\n-# notify slack\\n-notifications:\\n-  email: false\\n-  slack: ubcgif:1Z2lR3XYRSM3GHflG71ZHEN6\\ndiff --git a/README.md b/README.md\\nindex fd49b07..89ed791 100644\\n--- a/README.md\\n+++ b/README.md\\n@@ -2,7 +2,6 @@\\n \\n [![binder](https://mybinder.org/badge.svg)](https://mybinder.org/v2/gh/geoscixyz/geosci-labs/master?filepath=notebooks%2Findex.ipynb)\\n [![pypi](https://img.shields.io/pypi/v/geoscilabs.svg)](https://pypi.python.org/pypi/geoscilabs)\\n-[![travis](https://travis-ci.org/geoscixyz/geosci-labs.svg?branch=master)](https://travis-ci.org/geoscixyz/geosci-labs)\\n [![License](https://img.shields.io/github/license/geoscixyz/geosci-labs.svg)](https://github.com/geoscixyz/geosci-labs/blob/master/LICENSE)\\n [![SimPEG](https://img.shields.io/badge/powered%20by-SimPEG-blue.svg)](http://simpeg.xyz)\\n \\n',\n",
       " 'problem_statement': 'getting testing back up and running \\nWe can no longer rely on TravisCI for testing, so we should look at getting testing up and running elsewhere. What do folks think of using github actions for this (cc @jcapriot)? ',\n",
       " 'pull_number': 32,\n",
       " 'repo': 'geoscixyz/geosci-labs',\n",
       " 'test_patch': 'diff --git a/.github/workflows/tests.yml b/.github/workflows/tests.yml\\nnew file mode 100644\\nindex 0000000..1c96b69\\n--- /dev/null\\n+++ b/.github/workflows/tests.yml\\n@@ -0,0 +1,46 @@\\n+name: Testing\\n+\\n+on:\\n+  push:\\n+    branches:\\n+      - \\'*\\'\\n+  pull_request:\\n+    branches:\\n+      - \\'*\\'\\n+jobs:\\n+  setup-build:\\n+    name: Ex1 (${{ matrix.python-version }}, ${{ matrix.os }})\\n+    runs-on: ${{ matrix.os }}\\n+    strategy:\\n+      fail-fast: false\\n+      matrix:\\n+        os: [\"ubuntu-latest\"]\\n+        python-version: [3.7, 3.8]\\n+\\n+    steps:\\n+    - uses: actions/checkout@v2\\n+    - name: Setup Conda\\n+      uses: s-weigand/setup-conda@v1\\n+      with:\\n+        update-conda: true\\n+        conda-channels: conda-forge\\n+        python-version: ${{ matrix.python-version }}\\n+\\n+    - name: Install Env\\n+      shell: bash\\n+      run: |\\n+        python --version\\n+        conda env create -f environment-dev.yml\\n+\\n+    - name: Install Our Package\\n+      shell: bash\\n+      run: |\\n+        source activate geosci-labs-dev\\n+        pip install -e .\\n+        conda list\\n+\\n+    - name: Run Tests\\n+      shell: bash\\n+      run: |\\n+        source activate geosci-labs-dev\\n+        pytest .\\n'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeout_tasks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c71b184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os \n",
    "\n",
    "# fails = set([os.path.basename(t).split('.')[0] for t in failed_install if '0.0' not in t])\n",
    "\n",
    "# for t in sorted(tasks_dict):\n",
    "#     print(t, len(tasks_dict[t]), len(tasks_dict[t] & fails))\n",
    "\n",
    "# tasks_dict['tasks_0.json'] & fails\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2ac198",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ecf576b3-22ed-4d8c-a40d-340ae8c56db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logs same: 21425\n",
      "Logs diff: 6297\n"
     ]
    }
   ],
   "source": [
    "logs_same, logs_diff = monitor_logs_same_diff(log_dir)\n",
    "print(f\"Logs same: {len(logs_same)}\")\n",
    "print(f\"Logs diff: {len(logs_diff)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cdaf447f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Regex pattern to extract the module name\n",
    "pattern = r\"(?<=No module named ').*?(?=')\"\n",
    "\n",
    "def extract_module_name(error_message):\n",
    "    # Extracting the module name\n",
    "    match = re.search(pattern, error_message)\n",
    "    # Check if a match is found\n",
    "    if match:\n",
    "        return match.group(0)\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "08b0fc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "module_names = []\n",
    "for fp in logs_same:\n",
    "    with open(fp) as f:\n",
    "        l = f.read()\n",
    "        if \"ModuleNotFoundError\" in l:\n",
    "            module_names.append(extract_module_name(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c89cff5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c2bed78f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('responses', 184),\n",
       " ('mock', 177),\n",
       " ('hypothesis', 129),\n",
       " ('django', 125),\n",
       " ('freezegun', 104),\n",
       " ('_pytest._io', 97),\n",
       " ('jsonschema', 97),\n",
       " ('trustme', 75),\n",
       " ('sqlalchemy', 74),\n",
       " ('numpy', 72),\n",
       " ('PIL', 70),\n",
       " ('betamax', 60),\n",
       " ('vcr', 60),\n",
       " ('requests_mock', 56),\n",
       " (None, 54),\n",
       " ('docker', 51),\n",
       " ('tensorflow', 50),\n",
       " ('pytz', 44),\n",
       " ('requests', 43),\n",
       " ('pint.unit', 40),\n",
       " ('torch', 40),\n",
       " ('fastapi', 40),\n",
       " ('webtest', 38),\n",
       " ('_distutils_hack', 37),\n",
       " ('yaml', 37),\n",
       " ('attr', 37),\n",
       " ('lxml', 35),\n",
       " ('scripttest', 32),\n",
       " ('coverage_conditional_plugin', 29),\n",
       " ('pandas.tseries.tools', 27),\n",
       " ('asynctest', 26),\n",
       " ('httpretty', 24),\n",
       " ('pyspark', 24),\n",
       " ('pytest_recording', 24),\n",
       " ('jinja2', 24),\n",
       " ('jsonschema.compat', 22),\n",
       " ('mpi4py', 21),\n",
       " ('click', 18),\n",
       " ('pytest_timeout', 18),\n",
       " ('installer', 17),\n",
       " ('tvm', 17),\n",
       " ('dask.compatibility', 16),\n",
       " ('astropy.tests.pytest_plugins', 16),\n",
       " ('pkg_resources.extern', 15),\n",
       " ('selenium', 15),\n",
       " ('jax.config', 15),\n",
       " ('psycopg2', 15),\n",
       " ('sphinx', 14),\n",
       " ('azure', 14),\n",
       " ('dateutil', 14)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "Counter(module_names).most_common(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f06190f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/root/data/log_dir_2/jborchma__qtrade-7.log',\n",
       " '/root/data/log_dir_2/nolar__kopf-826.log',\n",
       " '/root/data/log_dir_2/OpenMDAO__dymos-240.log',\n",
       " '/root/data/log_dir_2/DataBiosphere__toil-3460.log',\n",
       " '/root/data/log_dir_2/dlint-py__dlint-49.log',\n",
       " '/root/data/log_dir_2/charettes__django-seal-36.log',\n",
       " '/root/data/log_dir_2/arviz-devs__arviz-557.log',\n",
       " '/root/data/log_dir_2/ros-infrastructure__bloom-614.log',\n",
       " '/root/data/log_dir_2/dpkp__kafka-python-1024.log',\n",
       " '/root/data/log_dir_2/mmagnuski__borsar-73.log']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logs_same[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "49c099bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tasks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81a74a5-c56e-4724-acf5-378b601a2d89",
   "metadata": {},
   "source": [
    "#### Get [FP]2[FP] Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb935466-43e8-45a7-8f46-15925d82312b",
   "metadata": {},
   "outputs": [],
   "source": [
    "inst_id_to_gt = {}\n",
    "for d in logs_diff:\n",
    "    status_gt = convert_log_to_ground_truth(d[0])\n",
    "    inst_id_to_gt[d[0]] = status_gt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccaa7863-f144-49da-ae92-6430841bd3ea",
   "metadata": {},
   "source": [
    "#### Create Task Instances `.json` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "44a4dc43-d158-4b3e-b7cd-728954bce188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final number of task instances:  1929\n"
     ]
    }
   ],
   "source": [
    "tasks_final = []\n",
    "get_id_from_log = lambda x: x.split('/')[-1].split('.')[0]\n",
    "for k, v in inst_id_to_gt.items():\n",
    "    if len(v['FAIL_TO_PASS']) == 0:\n",
    "        continue\n",
    "    if not get_id_from_log(k) in tasks:\n",
    "        continue\n",
    "    task = tasks[get_id_from_log(k)]\n",
    "    task['FAIL_TO_PASS'] = v['FAIL_TO_PASS']\n",
    "    task['PASS_TO_PASS'] = v['PASS_TO_PASS']\n",
    "    task['environment_setup_commit'] = version_to_setup_commit[\"0.0\"]\n",
    "\n",
    "    # Do not consider tasks where the log before the patch has an attribute/import error\n",
    "    log_path = os.path.join(log_dir, f'{task[\"instance_id\"]}.log')\n",
    "    log_before, log_after = get_logs_gold(log_path)\n",
    "    if has_attribute_or_import_error(log_before):\n",
    "        continue\n",
    "\n",
    "    tasks_final.append(task)\n",
    "print(f\"Final number of task instances: \", len(tasks_final))\n",
    "\n",
    "# SAVE_PATH = \"path/to/save/tasks/to.json\" # TODO: Replace this with a path to a .json file to save the task instances\n",
    "# with open(SAVE_PATH, 'w') as f:\n",
    "#     json.dump(tasks_final, fp=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e14fee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
